{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64470bd2",
   "metadata": {},
   "source": [
    "# Milestone 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d382c00e-5c98-4b60-a413-d7582ae1533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191a1ae",
   "metadata": {},
   "source": [
    "### 3. Downloading the data \n",
    "rubric={correctness:10}\n",
    "\n",
    "1. Download the data from [figshare](https://figshare.com/articles/dataset/Daily_rainfall_over_NSW_Australia/14096681) to your local computer using the [figshare API](https://docs.figshare.com) (you need to make use of `requests` library).\n",
    "\n",
    "2. Extract the zip file, again programmatically, similar to how we did it in class. \n",
    "\n",
    ">  You can download the data and unzip it manually. But we learned about APIs, so we can do it in a reproducible way with the `requests` library, similar to how we [did it in class](https://pages.github.ubc.ca/MDS-2022-23/DSCI_525_web-cloud-comp_students/lectures/lecture1.html#using-rest-api-lab-lecture).\n",
    "\n",
    "> There are 5 files in the figshare repo. The one we want is: `data.zip`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "588531e0-96d5-4fb0-a1a9-9b1d74c3ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced the below code from lecture notes \n",
    "\n",
    "article_id = 14096681 \n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = os.path.join(os.path.pardir, \"data/rainfall/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aed3ecd5-fa46-4a3c-b9e8-0565194267bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)  \n",
    "files = data[\"files\"]            \n",
    "files_to_dl = [\"data.zip\"]\n",
    "for file in files:\n",
    "    if file[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(file[\"download_url\"], output_directory + file[\"name\"])\n",
    "\n",
    "with zipfile.ZipFile(os.path.join(output_directory, \"data.zip\"), 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339101b5",
   "metadata": {},
   "source": [
    "### 4. Combining data CSVs\n",
    "rubric={correctness:10,reasoning:10}\n",
    "\n",
    "1. Combine data CSVs into a single CSV using pandas.\n",
    "    \n",
    "2. When combining the CSV files, add an extra column called \"model\" that identifies the model.\n",
    "    Tip 1: you can get this column populated from the file name, eg: for file name \"SAM0-UNICON_daily_rainfall_NSW.csv\", the model name is SAM0-UNICON\n",
    "    Tip 2: Remember how we added \"year\" column when we combined airline CSVs. Here the regex will be to get word before an underscore ie, \"/([^_]*)\"\n",
    "\n",
    "> Note: There is a file called `observed_daily_rainfall_SYD.csv` in the data folder that you downloaded. Make sure you exclude this file (programmatically or just take out that file from the folder) before you combine CSVs. We will use this file in our next milestone.\n",
    "\n",
    "3. ***Compare*** run times on different machines within your team and summarize your observations. \n",
    "\n",
    "> Warning: Some of you might not be able to do it on your laptop. It's fine if you're unable to do it. Just make sure you discuss the reasons why you might not have been able to run this on your laptop. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de3e0669-ac3c-49cd-bb40-21e13cb84fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 7s, sys: 35.3 s, total: 7min 42s\n",
      "Wall time: 8min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = glob.glob(os.path.join(os.path.pardir, \"data/rainfall/*.csv\"))\n",
    "files.remove(os.path.join(os.path.pardir, \"data/rainfall\", \"observed_daily_rainfall_SYD.csv\"))\n",
    "\n",
    "df = pd.concat((\n",
    "  pd.read_csv(file, index_col=0)\n",
    "  .assign(model=re.findall(\"([^_]*)\", os.path.basename(file))[0])\n",
    "  for file in files))\n",
    "df.to_csv(os.path.join(os.path.pardir, \"data/combined_data.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eddee7",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM          | Processor             | Is SSD | CPU time   | Wall time  |\n",
    "|:-----------:|:----------------:|:------------:|:---------------------:|:------:|:----------:|:----------:|\n",
    "| Rev         |MacOS             |8GB 3733MHz   |Intel i3 1.1GHz        |Yes     |6m56s       |7m47s       |\n",
    "| Caroline    |Windows 10        |16GB 3200MHz  |Intel i7-11800H 2.3GHz |Yes     |5m47s       |5m49s       |\n",
    "| Sneha       |Windows 11        |16GB 4800MHz  |Intel i7-12700H 2.3GHz |Yes     |5m20s       |5m39s       |\n",
    "| Renzo       |Windows 10        |8GB 2400MHz   |Intel i5-7300HQ 2.5GHz |Yes     |12m8s       |13m52s      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899637a",
   "metadata": {},
   "source": [
    "### 5. Load the combined CSV to memory and perform a simple EDA\n",
    "rubric={correctness:10,reasoning:10}\n",
    "\n",
    "1. Investigate at least two of the following approaches to reduce memory usage while performing the EDA (e.g., value_counts). \n",
    "    - Changing `dtype` of your data\n",
    "    - Load just columns that we want\n",
    "    - Loading in chunks\n",
    "    \n",
    "2. ***Compare*** run times on different machines within your team and summarize your observations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e8270",
   "metadata": {},
   "source": [
    "Saving memory usage: Using only certain columns (time, model, rain) and cast rain to float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f4ae60b-3d50-4afb-9c1d-926e8ea3e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 40.1 s\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "use_cols = ['time', 'rain (mm/day)', 'model']\n",
    "df = pd.read_csv(os.path.join(os.path.pardir, \"data/combined_data.csv\"), \n",
    "    usecols = use_cols)\n",
    "df['rain (mm/day)'] = df['rain (mm/day)'].astype('float32', errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf25bf7b-1ea0-432c-86ad-ee242b9aa329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.17 s\n",
      "Wall time: 2.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MPI-ESM1-2-HR       5154240\n",
       "TaiESM1             3541230\n",
       "NorESM2-MM          3541230\n",
       "CMCC-CM2-HR4        3541230\n",
       "CMCC-CM2-SR5        3541230\n",
       "CMCC-ESM2           3541230\n",
       "SAM0-UNICON         3541153\n",
       "FGOALS-f3-L         3219300\n",
       "GFDL-CM4            3219300\n",
       "GFDL-ESM4           3219300\n",
       "EC-Earth3-Veg-LR    3037320\n",
       "MRI-ESM2-0          3037320\n",
       "BCC-CSM2-MR         3035340\n",
       "MIROC6              2070900\n",
       "ACCESS-CM2          1932840\n",
       "ACCESS-ESM1-5       1610700\n",
       "INM-CM5-0           1609650\n",
       "INM-CM4-8           1609650\n",
       "KIOST-ESM           1287720\n",
       "FGOALS-g3           1287720\n",
       "MPI-ESM1-2-LR        966420\n",
       "NESM3                966420\n",
       "AWI-ESM-1-1-LR       966420\n",
       "MPI-ESM-1-2-HAM      966420\n",
       "NorESM2-LM           919800\n",
       "BCC-ESM1             551880\n",
       "CanESM5              551880\n",
       "Name: model, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "df['model'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f2a8906-a45d-4497-a1c9-c75e3a88445e",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM          | Processor             | Is SSD | CPU time (dtype,column)  | Wall time(dtype,column)  |\n",
    "|:-----------:|:----------------:|:------------:|:---------------------:|:------:|:----------:|:----------:|\n",
    "| Rev         |MacOS             |8GB 3733MHz   |Intel i3 1.1GHz        |Yes     |55.3s, 2.94s       |1m39s 3.1s       |\n",
    "| Caroline    |Windows 10        |16GB 3200MHz  |Intel i7-11800H 2.3GHz |Yes     |40.1s, 2.17s       |40.8s, 2.18s      |\n",
    "| Sneha       |Windows 11        |16GB 4800MHz  |Intel i7-12700H 2.3GHz |Yes     |       |      |\n",
    "| Renzo       |Windows 10        |8GB 2400MHz   |Intel i5-7300HQ 2.5GHz |Yes     |       |      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355ea6fc-6b7d-4b46-9aad-2fd88441d89a",
   "metadata": {},
   "source": [
    "### 6. Perform a simple EDA in R\n",
    "rubric={correctness:15,reasoning:10}\n",
    "\n",
    "1. Choose one of the methods listed below for transferring the dataframe (i.e., the entire dataset) from Python to R, and explain why you opted for this approach instead of the others.\n",
    "    - [Parquet file](http://parquet.apache.org)\n",
    "    - [Pandas exchange](https://rpy2.github.io/doc/latest/html/interactive.html)\n",
    "    - [Arrow exchange](https://github.com/rpy2/rpy2-arrow)\n",
    "2. Once you have the dataframe in R, perform a simple EDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad9775-1b85-499c-82be-7b86f930df80",
   "metadata": {},
   "source": [
    "We chose Arrow exchange method because it is more efficient than the other two methods. Arrow exchange method does not require serialization and de-serialization which makes the process of transfer of data between R and Python more efficient and faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e4650-4c2e-426d-a788-987c23445e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rpy2_arrow\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "import pyarrow \n",
    "from pyarrow import csv\n",
    "import rpy2_arrow.pyarrow_rarrow as pyra\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10ab36-3a0c-4011-b6a2-59f27dd37270",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6a8ee41-adfe-4b11-a685-c5714ad7de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/revathypon/525/525-group-11/data/combined_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb58d869-f870-4476-a23c-aab9468ab4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 4.65 s, total: 26.4 s\n",
      "Wall time: 24.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "csv_data = ds.dataset(path, format=\"csv\")\n",
    "# Converting the `pyarrow dataset` to a `pyarrowtable`\n",
    "table = csv_data.to_table()\n",
    "# Converting a `pyarrow table` to a `rarrow table`\n",
    "r_table = pyra.converter.py2rpy(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db737b5d-31d7-4dd7-bc1a-8d3e6088face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 27 × 2\n",
      "   model                  n\n",
      "   <chr>              <int>\n",
      " 1 MPI-ESM-1-2-HAM   966420\n",
      " 2 AWI-ESM-1-1-LR    966420\n",
      " 3 NorESM2-LM        919800\n",
      " 4 ACCESS-CM2       1932840\n",
      " 5 FGOALS-f3-L      3219300\n",
      " 6 CMCC-CM2-HR4     3541230\n",
      " 7 MRI-ESM2-0       3037320\n",
      " 8 GFDL-CM4         3219300\n",
      " 9 BCC-CSM2-MR      3035340\n",
      "10 EC-Earth3-Veg-LR 3037320\n",
      "# ℹ 17 more rows\n",
      "# ℹ Use `print(n = ...)` to see more rows\n",
      "CPU times: user 3.59 s, sys: 2.45 s, total: 6.04 s\n",
      "Wall time: 5.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%%R -i r_table\n",
    "\n",
    "suppressMessages(library(dplyr))\n",
    "output <- r_table |> count(model)|> collect()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d77c1-c736-46be-9f5e-7acbce88d18e",
   "metadata": {},
   "source": [
    "| Team Member | Operating System | RAM          | Processor             | Is SSD | CPU time   | Wall time  |\n",
    "|:-----------:|:----------------:|:------------:|:---------------------:|:------:|:----------:|:----------:|\n",
    "| Rev         |MacOS             |8GB 3733MHz   |Intel i3 1.1GHz        |Yes     |21.7s       |24.7s       |\n",
    "| Caroline    |Windows 10        |16GB 3200MHz  |Intel i7-11800H 2.3GHz |Yes     |       |       |\n",
    "| Sneha       |Windows 11        |16GB 4800MHz  |Intel i7-12700H 2.3GHz |Yes     |       |      |\n",
    "| Renzo       |Windows 10        |8GB 2400MHz   |Intel i5-7300HQ 2.5GHz |Yes     |       |      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c20c29-3b94-48d3-a039-ba0629566740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "525_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
